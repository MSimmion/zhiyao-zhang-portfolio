{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPl/4pJodMDvtEXC1qzw/Qu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"nyjTe_Q0NO0J"},"outputs":[],"source":["from sklearn.metrics import mean_squared_error\n","def compute_mse(Z, Y):\n","    \"\"\"\n","    Compute the mean squared error (MSE) between predictions and ground truth.\n","\n","    Parameters:\n","        Z (ndarray or csr_matrix): Predicted probabilities (n_nodes x n_classes).\n","        Y (ndarray or csr_matrix): Ground truth labels (n_nodes x n_classes).\n","\n","    Returns:\n","        float: Mean squared error.\n","    \"\"\"\n","    if hasattr(Z, \"toarray\"):  # Check if Z is sparse\n","        Z = Z.toarray()\n","    if hasattr(Y, \"toarray\"):  # Check if Y is sparse\n","        Y = Y.toarray()\n","\n","    mse = np.mean((Z - Y) ** 2)  # Element-wise difference squared and mean\n","    return mse\n","\n","\n","def softmax(X):\n","    \"\"\"\n","    Compute the softmax of each row of the matrix X, supporting both sparse and dense inputs.\n","\n","    Parameters:\n","        X (csr_matrix or ndarray): Input matrix (n_nodes x n_classes).\n","\n","    Returns:\n","        csr_matrix or ndarray: Matrix with softmax applied row-wise.\n","    \"\"\"\n","    if isinstance(X, csr_matrix):\n","        # Sparse matrix handling\n","        X_dense = X.toarray()  # Convert sparse matrix to dense\n","        exp_X = np.exp(X_dense - np.max(X_dense, axis=1, keepdims=True))  # Stability\n","        row_sums = np.sum(exp_X, axis=1, keepdims=True)\n","        softmax_dense = exp_X / row_sums\n","        return csr_matrix(softmax_dense)  # Convert back to sparse\n","    else:\n","        # Dense matrix handling\n","        exp_X = np.exp(X - np.max(X, axis=1, keepdims=True))  # Stability\n","        row_sums = np.sum(exp_X, axis=1, keepdims=True)\n","        return exp_X / row_sums\n","\n","\n","\n","def appnp(adj_matrix, H, alpha=0.1, K=10):\n","    \"\"\"\n","    Implement the APPNP algorithm.\n","\n","    Parameters:\n","        adj_matrix (ndarray or csr_matrix): The adjacency matrix of the graph.\n","        H (ndarray): Initial node feature matrix (n_nodes x n_features).\n","        alpha (float): Teleport probability.\n","        K (int): Number of iterations.\n","\n","    Returns:\n","        Z (ndarray): Final predictions after propagation.\n","    \"\"\"\n","    # Normalize the adjacency matrix\n","    adj_matrix = csr_matrix(adj_matrix)  # Ensure sparse matrix\n","    normalized_adj = normalize_adjacency(adj_matrix)\n","\n","    # Initialize Z^(0)\n","    Z = H.copy()\n","\n","    # Iterative propagation\n","    for _ in range(K):\n","        Z = (1 - alpha) * normalized_adj @ Z + alpha * H\n","\n","    # Apply softmax at the end\n","    Z = softmax(Z)\n","    return Z"]},{"cell_type":"code","source":[],"metadata":{"id":"soaadjisNSq2"},"execution_count":null,"outputs":[]}]}